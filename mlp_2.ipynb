{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jHXOKwRh_uq"
      },
      "source": [
        "# Standard library\n",
        "import random\n",
        "\n",
        "# Third-party libraries\n",
        "import numpy as np\n",
        "# Definición de la clase Network\n",
        "\n",
        "def feedforward(x,bias,weight):\n",
        "    \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
        "\n",
        "    print(\"w\")\n",
        "    print(weight)\n",
        "    print(\"x\")\n",
        "    print(x)\n",
        "    print(\"b\")\n",
        "    print(bias)\n",
        "    for b, w in zip(bias, weight):\n",
        "        z=np.dot(w, x)+b\n",
        "        a = sigmoid(z)\n",
        "    print('a')\n",
        "    print(a)\n",
        "\n",
        "    return a\n",
        "\n",
        "#### Miscellaneous functions\n",
        "def sigmoid(z):\n",
        "    \"\"\"The sigmoid function.\"\"\"\n",
        "    return 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
        "    return sigmoid(z)*(1-sigmoid(z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tjq1KH4_M9M",
        "outputId": "db863c1a-2884-430b-f325-f5e771180ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "import numpy as np\n",
        "sizes = [2,2,1]\n",
        "num_layers = len(sizes)\n",
        "#weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
        "weights = [np.array([[ 0.00771645, -0.87215412],[-0.8828999 ,  0.91634591]]), np.array([[-0.27296355, -0.16419596]])]\n",
        "print(\"weights: w[input neuron,output neuron]  ---  [[w_1,1^2][w_1,2^2]][[w_2,1^2][w_2,2^2]] ---  [[w_1,1^3][w_1,2^3]] [2, 2] [2, 1]\")\n",
        "print(sizes[:-1], sizes[1:]) # [:-1] desde el inicio hasta el ultimo (sin incluirlo) [2,2] (desde el primero sin el ultimo)\n",
        "print(weights)\n",
        "\n",
        "#biases = [np.random.randn(y,1) for y in sizes[1:]]\n",
        "biases = [np.array([[-0.37810527], [ 0.30153513]]), np.array([[0.83487797]])]\n",
        "print(\"biases: b[input layer,input neuron] --- [[b_1^2] [b_2^2]] [[b_1^3]] --- [2, 1]\")\n",
        "print(sizes[1:]) # [1:] desde el indice 1 hasta el ultimo [2,1]\n",
        "print(biases)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: w[input neuron,output neuron]  ---  [[w_1,1^2][w_1,2^2]][[w_2,1^2][w_2,2^2]] ---  [[w_1,1^3][w_1,2^3]] [2, 2] [2, 1]\n",
            "[2, 2] [2, 1]\n",
            "[array([[ 0.00771645, -0.87215412],\n",
            "       [-0.8828999 ,  0.91634591]]), array([[-0.27296355, -0.16419596]])]\n",
            "biases: b[input layer,input neuron] --- [[b_1^2] [b_2^2]] [[b_1^3]] --- [2, 1]\n",
            "[2, 1]\n",
            "[array([[-0.37810527],\n",
            "       [ 0.30153513]]), array([[0.83487797]])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ccqwou70VxyP",
        "outputId": "81e973dc-d045-401c-e69e-f0cbe743a498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print('1. Inicializar los patrones de entrada x con sus respectivos objetivos t:')\n",
        "X = np.array([[0,0],\n",
        "              [0,1],\n",
        "              [1,0],\n",
        "              [1,1]])\n",
        "\n",
        "print('x= \\n {}'.format(X))\n",
        "T = np.array([[1],\n",
        "             [0],\n",
        "             [0],\n",
        "             [1]])\n",
        "\n",
        "print('t= \\n{}'.format(t))\n",
        "alpha=0.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1. Inicializar los patrones de entrada x con sus respectivos objetivos t:\n",
            "x= \n",
            " [[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]]\n",
            "t= \n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHQZadsp_SLw",
        "outputId": "a092e652-8e92-4088-ddf0-df7580fa1c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 1. Feed-forward: pasar el patron de entrada por todas la capas\n",
        "dC_db = [np.zeros(b.shape) for b in biases]\n",
        "dC_dw = [np.zeros(w.shape) for w in weights]\n",
        "\n",
        "for x,t in zip(X,T):\n",
        "    print('-------------------------patrón: {}'.format(x))\n",
        "    print(x)\n",
        "    print(t)\n",
        "    #a=feedforward(x,biases,weights)\n",
        "    a_list = [x] # list to store all the activations, layer by layer\n",
        "    z_list = [] # list to store all the z vectors, layer by layer\n",
        "\n",
        "    for b, w in zip(biases, weights):\n",
        "        z = np.dot(w,a_list[-1].transpose())+b.transpose()\n",
        "        z_list.append(z)\n",
        "        a = sigmoid(z)\n",
        "        a_list.append(a)\n",
        "\n",
        "    print(\"a_list = \")\n",
        "    print(a_list)\n",
        "    # 2. output error\n",
        "    C = (0.5*(t-a_list[-1])**2).mean(axis=0) #indice [-1] significa el último elemento de la lista, correspondiente a la última capa\n",
        "    print('C = {}'.format(C))\n",
        "\n",
        "    # 3. back propagation\n",
        "    delta_list = []\n",
        "    print(z_list)\n",
        "    # 3.1 BP: error de la capa de salida ###############################################################################\n",
        "    delta_L = -(t-a_list[-1])*sigmoid_prime(z_list[-1]) #delta^L = [delta_1^3]\n",
        "    #delta_L = -np.dot((t-a_list[-1]),sigmoid_prime(z_list[-1])) #delta^L = [delta_1^3]\n",
        "    print(\"delta L = {}\".format(delta_L)) # [delta_1^3]\n",
        "    #delta_list.append(delta_L[0])\n",
        "    delta_list.insert(0,delta_L[0])\n",
        "    print(delta_list)\n",
        "    #  3.2 BP: calcular la actualizacion de los pesos y bias en L\n",
        "    #dC_dw[-1] = np.dot(delta_list[-1], a_list[-2]) #1x1 1x4 = 1x4\n",
        "    dC_dw[-1] = delta_list[-1]*a_list[-2]\n",
        "    print('dc_dw: {}'.format(dC_dw[-1]))\n",
        "    #dC_dw[-1] = np.dot(delta_L, a_list[-2]) #1x1 1x4 = 1x4\n",
        "\n",
        "    w_new = weights[-1] - alpha*dC_dw[-1] # 1x2   [w_1,1^3][w_1,2^3] ---> new\n",
        "    print('new weights: ')\n",
        "    print(w_new)\n",
        "\n",
        "    dC_db[-1] = delta_list[-1] #1x1\n",
        "    print('dc_db: {}'.format(dC_db[-1]))\n",
        "    b_new = biases[-1].transpose()  - alpha*dC_db[-1]   # [b_1^3] --> new\n",
        "    print('new bias: ')\n",
        "    print(b_new)\n",
        "    biases[-1] = b_new   #1x1\n",
        "    weights[-1] = w_new  #1x2\n",
        "\n",
        "\n",
        "    print('3.3 BP: error de la capa oculta') #################################################################################\n",
        "    delta_l = delta_list[-1]*weights[-1]*sigmoid_prime(z_list[-2]) # 1x1 1x2 o 1x2\n",
        "    print('delta_l')\n",
        "    #print(delta_l)\n",
        "    delta_list.insert(0,delta_l[-1]) # como append, pero agrega el elemento al principio y desplaza los existentes\n",
        "    #print('delta_list despues de append')\n",
        "    print(delta_list)\n",
        "\n",
        "    #print('3.4 BP: calcular los pesos y bias de la capa oculta')\n",
        "    #print('delta_list: {}'.format(delta_list[-2]))\n",
        "    #print('a_list: {}'.format(a_list[-3]))\n",
        "    #dC_dw[-2] = np.matmul(delta_list[-2],a_list[-3]) #1x1 1x4 = 1x4\n",
        "    dC_dw[-2] = delta_list[-2]*a_list[-3]\n",
        "    #dC_dw[-2] = delta_list[-2]* a_list[-3] #1x1 1x4 = 1x4\n",
        "    print('dc_dw: {}'.format(dC_dw[-2]))\n",
        "    w_new = weights[-2] - alpha*dC_dw[-2] # 2x2   [w_1,1^2][w_1,2^2][w_2,1^2][w_2,2^2] ---> new\n",
        "    print('new weights: ')\n",
        "    print(w_new)\n",
        "\n",
        "    dC_db[-2] = delta_list[-2] #1x1\n",
        "    print('dc_db: {}'.format(dC_db[-2]))\n",
        "    #print('biases: {}'.format(biases[-2]))\n",
        "    b_new = biases[-2].transpose()  - alpha*dC_db[-2]   # [b_1^2] [b_2^2] --> new\n",
        "    print('new bias: ')\n",
        "    print(b_new)\n",
        "    biases[-2] = b_new   #1x1\n",
        "    weights[-2] = w_new  #1x2\n",
        "\n",
        "\n",
        "\n",
        "    print(\"weights despues\")\n",
        "    print(weights)\n",
        "\n",
        "    print(\"biases despues\")\n",
        "    print(biases)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------patrón: [0 0]\n",
            "[0 0]\n",
            "[1]\n",
            "a_list = \n",
            "[array([0, 0]), array([[0.40658396, 0.57481775]]), array([[0.65237894]])]\n",
            "C = [0.0604202]\n",
            "[array([[-0.37810527,  0.30153513]]), array([[0.62951262]])]\n",
            "delta L = [[-0.07883373]]\n",
            "[array([-0.07883373])]\n",
            "dc_dw: [[-0.03205253 -0.04531503]]\n",
            "new weights: \n",
            "[[-0.25693728 -0.14153845]]\n",
            "dc_db: [-0.07883373]\n",
            "new bias: \n",
            "[[0.87429484]]\n",
            "3.3 BP: error de la capa oculta\n",
            "delta_l\n",
            "[[0.00488707 0.00272704]]\n",
            "delta_list despues de append\n",
            "[array([0.00488707, 0.00272704]), array([-0.07883373])]\n",
            "3.4 BP: calcular los pesos y bias de la capa oculta\n",
            "delta_list: [0.00488707 0.00272704]\n",
            "a_list: [0 0]\n",
            "dc_dw: [0. 0.]\n",
            "new weights: \n",
            "[[ 0.00771645 -0.87215412]\n",
            " [-0.8828999   0.91634591]]\n",
            "dc_db: [0.00488707 0.00272704]\n",
            "biases: [[-0.37810527]\n",
            " [ 0.30153513]]\n",
            "new bias: \n",
            "[[-0.38054881  0.30017161]]\n",
            "weights despues\n",
            "[array([[ 0.00771645, -0.87215412],\n",
            "       [-0.8828999 ,  0.91634591]]), array([[-0.25693728, -0.14153845]])]\n",
            "biases despues\n",
            "[array([[-0.38054881,  0.30017161]]), array([[0.87429484]])]\n",
            "-------------------------patrón: [0 1]\n",
            "[0 1]\n",
            "[0]\n",
            "a_list = \n",
            "[array([0, 1]), array([[0.2222326 , 0.63083418],\n",
            "       [0.3607795 , 0.77145012]]), array([[0.67434597, 0.66204198]])]\n",
            "C = [0.22737124 0.21914979]\n",
            "[array([[-1.25270293,  0.5357971 ],\n",
            "       [-0.57198251,  1.21651752]]), array([[0.72790771, 0.67240728]])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-208-9988977c9b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mdelta_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mdelta_L\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigmoid_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#delta^L = [delta_1^3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"delta L = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_L\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [delta_1^3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mdelta_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_L\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (1,2) and (1,2) not aligned: 2 (dim 1) != 1 (dim 0)"
          ]
        }
      ]
    }
  ]
}